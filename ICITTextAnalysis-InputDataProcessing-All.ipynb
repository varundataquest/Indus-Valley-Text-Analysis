{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de1a3034",
   "metadata": {},
   "source": [
    "# Indus Valley Script- Text Analysis for Decipherment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "838b03a1",
   "metadata": {},
   "source": [
    "## Input data processing and data cleanup\n",
    "\n",
    "This file is used to process the Input data, clean it up and create various pickled dataframes.\n",
    "Dataset was created as a csv file from ICIT web site from raw html files of ICIT code for each for the Text\n",
    "Data labels were changes and a linearized copy of the original text was added\n",
    "\n",
    "### Input:\n",
    "icit_text_text_corpus.csv and icit_sign_corpus.csv are the input csv\n",
    "\n",
    "### Output:\n",
    "Various Pickled dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84c5b49",
   "metadata": {},
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn\n",
    "!pip install nltk\n",
    "!pip install ipywidgets\n",
    "!pip install -U dill\n",
    "!pip3 install requests\n",
    "!pip3 install -U spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa43bd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "import collections\n",
    "import random\n",
    "import traceback\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "057c8bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import pad_sequence\n",
    "from nltk.util import bigrams\n",
    "from nltk.util import ngrams\n",
    "from nltk.util import everygrams\n",
    "from nltk.lm.preprocessing import pad_both_ends\n",
    "from nltk.lm.preprocessing import flatten\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7004991",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_duplicate_texts = True\n",
    "\n",
    "# Set the filters on data here\n",
    "filter_by_site = False\n",
    "filter_by_keywords = False\n",
    "filter_by_text_length= False\n",
    "\n",
    "#site = 'Mohenjo-daro'\n",
    "#site = 'Harappa'\n",
    "#site = 'Dholavira'\n",
    "#site = 'Rakhigarhi'\n",
    "#keyword = \"Bull\"\n",
    "#keyword = \"Gaur\"\n",
    "\n",
    "min_text_length=1\n",
    "max_text_length=50\n",
    "\n",
    "num_rows_text_corpus= 4999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d54305a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "709\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Read the signs\"\"\"\n",
    "orig_sign_df=pd.read_csv('../../IndusCorpusUtils/data/icit_corpus/icit_sign_corpus.csv',dtype=str)\n",
    "\n",
    "\"\"\"Set the max columns to none\"\"\"\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(len(orig_sign_df))\n",
    "\n",
    "\"\"\"Pickle it\"\"\"\n",
    "orig_sign_df.to_pickle('pickle/orig_sign_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49bd36ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Read the Text Corpus\"\"\"\n",
    "orig_df=pd.read_csv('../../IndusCorpusUtils/data/icit_corpus/icit_text_text_corpus.csv',dtype=str, nrows=num_rows_text_corpus)\n",
    "# set the max columns to none\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2b92e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has  4999  rows\n",
      "     icit_id        site keywords text_class lines direction       text signs  \\\n",
      "0          1  Alamgirpur      NaN         SS     1       L/R  +410-017+     2   \n",
      "1          2  Alamgirpur      NaN         SS     1       L/R  +410-017+     2   \n",
      "2          3  Alamgirpur      NaN         SC     1       L/R  +405-017+     2   \n",
      "3          4   Allahdino      NaN         ??     1       NaN  +220-000+     1   \n",
      "4          5   Allahdino     Bull         UC     1       R/L  +740-235+     2   \n",
      "...      ...         ...      ...        ...   ...       ...        ...   ...   \n",
      "4994    4064     Harappa      NaN         UC     1       NaN      +000[     0   \n",
      "4995    4065     Harappa      NaN         VN     1       R/L  ]700-032[     2   \n",
      "4996    4065     Harappa      NaN         UC     1       R/L  ]000-000[     0   \n",
      "4997    4066     Harappa      NaN         UC     1       R/L  +368-000+     1   \n",
      "4998    4066     Harappa      NaN         VN     1       R/L  +700-033+     2   \n",
      "\n",
      "     complete    alignment  sign height text_images linearized_text  \\\n",
      "0           Y    Unordered      Unequal         NaN         410 017   \n",
      "1           Y          NaN          NaN         NaN         410 017   \n",
      "2           Y          NaN          NaN         NaN         405 017   \n",
      "3           N          NaN          NaN         NaN         220 000   \n",
      "4           Y          NaN          NaN         NaN         740 235   \n",
      "...       ...          ...          ...         ...             ...   \n",
      "4994        N  Indefinable  Indefinable         NaN            000[   \n",
      "4995        ?          NaN          NaN         NaN        700 032[   \n",
      "4996        N          NaN          NaN         NaN        000 000[   \n",
      "4997        N          NaN          NaN         NaN         368 000   \n",
      "4998        Y          NaN          NaN         NaN         700 033   \n",
      "\n",
      "     l_to_r_text r_to_l_text reversed_text  text_length  \n",
      "0        410 017     017 410       017 410          2.0  \n",
      "1        410 017     017 410       017 410          2.0  \n",
      "2        405 017     017 405       017 405          2.0  \n",
      "3        000 220     000 220       220 000          2.0  \n",
      "4        235 740     740 235       740 235          2.0  \n",
      "...          ...         ...           ...          ...  \n",
      "4994        000[        000[          000[          1.0  \n",
      "4995    032[ 700    700 032[      700 032[          3.0  \n",
      "4996    000[ 000    000 000[      000 000[          3.0  \n",
      "4997     000 368     368 000       368 000          2.0  \n",
      "4998     033 700     700 033       700 033          2.0  \n",
      "\n",
      "[4999 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Reverse text and add that as a new column\"\"\"\n",
    "\"\"\" Add text length as a column \"\"\"\n",
    "list_reversed_text = []\n",
    "for text in orig_df[orig_df.l_to_r_text!=''].l_to_r_text:\n",
    "    # Tokenize to words\n",
    "    # first split the string into chars\n",
    "    chars = text.split(' ')\n",
    "    length = len(chars)\n",
    "    # then reverse the split string list and join with a space\n",
    "    reversed_text = ' '.join(reversed(chars))\n",
    "    list_reversed_text.append(reversed_text)\n",
    "    \n",
    "orig_df['reversed_text']= list_reversed_text #same as r_to_l text\n",
    "orig_df['text_length']= orig_df['l_to_r_text'].str.len().div(3).round()\n",
    "\n",
    "print(\"Dataframe has \", len(orig_df.index), \" rows\")\n",
    "\n",
    "print(orig_df)\n",
    "\n",
    "\"\"\"Pickle it\"\"\"\n",
    "orig_df.to_pickle('pickle/upd_orig_df.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3353f8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = orig_df.copy()\n",
    "\n",
    "if(filter_by_site==True):\n",
    "    #keep only the values that matches the provided site\n",
    "    df = df[df['site'].str.contains(site) == True] \n",
    "    print(\"After filtering by site \", site, \" it has \", len(df.index), \" rows\")\n",
    "\n",
    "if(filter_by_keywords==True):\n",
    "     #keep only the values that matches the provided keyword\n",
    "    df = df[df['keywords'].str.contains(keyword) == True] \n",
    "    print(\"After filtering by keywords \", keyword, \" it has \", len(df.index), \" rows\")\n",
    "\n",
    "if(filter_by_text_length==True):\n",
    "    df = df[(df['text_length'] > min_text_length) & (df['text_length']< max_text_length)]\n",
    "    print(\"After filtering by text_length \",  \" it has \", len(df.index), \" rows\")\n",
    "\n",
    "\n",
    "df_filtered = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa8749f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing unclear texts, we have  3945  rows\n",
      "After removing duplicate texts, we have  2856  rows\n",
      "After removing multi-line text, we have  2778  rows\n",
      "After keeping only text with known direction, we have  2646  rows\n",
      "After keeping only text without multipart, we have  2223  rows\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Retain texts that are only wanted \"\"\"\n",
    "\n",
    "\"\"\" remove the values where the text is unclear\"\"\"\n",
    "df = df[df['l_to_r_text'].str.contains('000') == False] \n",
    "\n",
    "print(\"After removing unclear texts, we have \", len(df.index), \" rows\")\n",
    "\n",
    "if(drop_duplicate_texts):\n",
    "    #Remove out duplicate inplace\n",
    "    \n",
    "    # We will consider a text duplicate only of the keywords(pics) are different\n",
    "    # In that case we will retain the first occurance of it\n",
    "    df = df.drop_duplicates(subset =[\"text\", \"keywords\", \"site\"], inplace = False, keep = \"first\")\n",
    "    print(\"After removing duplicate texts, we have \", len(df.index), \" rows\")\n",
    "\n",
    "\n",
    "#keep only the values that does not have multi-line text\n",
    "df = df[df['text'].str.contains('/') == False] \n",
    "\n",
    "print(\"After removing multi-line text, we have \", len(df.index), \" rows\")\n",
    "\n",
    "\n",
    "#Single sign ones don't have direction and won't have /, wo we need to explicitly include it\n",
    "#Btw standardized_text is Left to right as in English\n",
    "df = df[(df['direction'].str.contains('/') == True) | (df['text_length'] ==1)] \n",
    "\n",
    "print(\"After keeping only text with known direction, we have \", len(df.index), \" rows\")\n",
    "\n",
    "#Remove Multipart texts that have [ or ]\n",
    "df = df[df['text'].str.contains(\"\\[\") == False] \n",
    "df = df[df['text'].str.contains(\"\\]\") == False] \n",
    "\n",
    "print(\"After keeping only text without multipart, we have \", len(df.index), \" rows\")\n",
    "\n",
    "\"\"\"Pickle it\"\"\"\n",
    "df.to_pickle('pickle/clean_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b56653c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L/R texts:  97\n",
      "R/L texts:  1985\n"
     ]
    }
   ],
   "source": [
    "\"\"\" of those whose direction is know print out L/R and L/R text count\"\"\"\n",
    "df_l_r = df[df['direction'].str.contains('L/R') == True] \n",
    "\n",
    "print(\"L/R texts: \", len(df_l_r.index))\n",
    "\n",
    "df_r_l = df[df['direction'].str.contains('R/L') == True]\n",
    "\n",
    "print(\"R/L texts: \", len(df_r_l.index))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30271f44",
   "metadata": {},
   "source": [
    "# Indus core region Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ecc97810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing Indus non-core region  site  ['Altin Yepe', 'Hajar', \"Ra's al-Junayz\", \"Qala'at al-Bahrain\", 'Failaka', 'Kish', 'Nippur', 'Luristan', 'Susa', 'Altyn Depe', 'Tepe Yahya', 'Tello', 'Ur', 'Tell Umma', 'Gonur Depe']  it has  2213  rows\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Keep Indus core region site texts, removing others\"\"\"\n",
    "indus_non_core_sites = ['Altin Yepe', 'Hajar', 'Ra\\'s al-Junayz', 'Qala\\'at al-Bahrain', 'Failaka', 'Kish', 'Nippur','Luristan', 'Susa', 'Altyn Depe', 'Tepe Yahya', 'Tello', 'Ur', 'Tell Umma', 'Gonur Depe']\n",
    "    \n",
    "df_indus_core_region = df.copy()\n",
    "    \n",
    "for indus_non_core_site in indus_non_core_sites:\n",
    "    df_indus_core_region = df_indus_core_region[df_indus_core_region['site'].str.contains(indus_non_core_site) == False]\n",
    "    \n",
    "print(\"After removing Indus non-core region  site \", indus_non_core_sites , \" it has \", len(df_indus_core_region.index), \" rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3fc826",
   "metadata": {},
   "source": [
    "# Indus non core region Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55b9cf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indus non-core region site texts ['Altin Yepe', 'Hajar', \"Ra's al-Junayz\", \"Qala'at al-Bahrain\", 'Failaka', 'Kish', 'Nippur', 'Luristan', 'Susa', 'Altyn Depe', 'Tepe Yahya', 'Tello', 'Ur', 'Tell Umma', 'Gonur Depe']  has  10  rows\n",
      "     icit_id                site             keywords text_class lines  \\\n",
      "4782    3884           Tell Umma                Bull1         PP     1   \n",
      "4796    3897                  Ur                 Gaur         SC     1   \n",
      "4797    3898                  Ur                 Gaur         UC     1   \n",
      "15        16          Altyn Depe                  NaN         UC     1   \n",
      "4780    3882                Susa                 Gaur         LC     1   \n",
      "2928    2153            Luristan                 Gaur         SC     1   \n",
      "2721    1971                Kish             Bull1:II         LP     1   \n",
      "4758    3863  Qala'at al-Bahrain                 Gaur         SC     1   \n",
      "4760    3865      Ra's al-Junayz                  NaN         SS     1   \n",
      "161      160               Hajar  Gaur:Scene, 2 Goats         SS     1   \n",
      "\n",
      "     direction                               text signs complete  \\\n",
      "4782       R/L              +390-004-002-705-127+     5        Y   \n",
      "4796       R/L              +093-340-924-220-528+     5        Y   \n",
      "4797       R/L          +002-004-328-001-803-415+     6        Y   \n",
      "15         L/R                          +390-415+     2        Y   \n",
      "4780       R/L  +416-150-002-055-031-319-001-924+     8        Y   \n",
      "2928       R/L                  +831-413-840-091+     4        Y   \n",
      "2721       R/L  +740-390-590-220-003-060-840-416+     8        Y   \n",
      "4758       L/R              +160-090-055-060-190+     5        Y   \n",
      "4760       R/L                          +405-004+     2        Y   \n",
      "161        R/L                          +617-117+     2        Y   \n",
      "\n",
      "          alignment sign height text_images                  linearized_text  \\\n",
      "4782            NaN         NaN         NaN              390 004 002 705 127   \n",
      "4796  Partly linear     Unequal         NaN              093 340 924 220 528   \n",
      "4797  Partly linear     Unequal         NaN          002 004 328 001 803 415   \n",
      "15           Linear       Equal         NaN                          390 415   \n",
      "4780  Partly linear       Equal         NaN  416 150 002 055 031 319 001 924   \n",
      "2928         Linear     Unequal         NaN                  831 413 840 091   \n",
      "2721         Linear       Equal         NaN  740 390 590 220 003 060 840 416   \n",
      "4758      Unordered     Unequal         NaN              160 090 055 060 190   \n",
      "4760            NaN         NaN         NaN                          405 004   \n",
      "161             NaN         NaN         NaN                          617 117   \n",
      "\n",
      "                          l_to_r_text                      r_to_l_text  \\\n",
      "4782              127 705 002 004 390              390 004 002 705 127   \n",
      "4796              528 220 924 340 093              093 340 924 220 528   \n",
      "4797          415 803 001 328 004 002          002 004 328 001 803 415   \n",
      "15                            390 415                          415 390   \n",
      "4780  924 001 319 031 055 002 150 416  416 150 002 055 031 319 001 924   \n",
      "2928                  091 840 413 831                  831 413 840 091   \n",
      "2721  416 840 060 003 220 590 390 740  740 390 590 220 003 060 840 416   \n",
      "4758              160 090 055 060 190              190 060 055 090 160   \n",
      "4760                          004 405                          405 004   \n",
      "161                           117 617                          617 117   \n",
      "\n",
      "                        reversed_text  text_length  \n",
      "4782              390 004 002 705 127          6.0  \n",
      "4796              093 340 924 220 528          6.0  \n",
      "4797          002 004 328 001 803 415          8.0  \n",
      "15                            415 390          2.0  \n",
      "4780  416 150 002 055 031 319 001 924         10.0  \n",
      "2928                  831 413 840 091          5.0  \n",
      "2721  740 390 590 220 003 060 840 416         10.0  \n",
      "4758              190 060 055 090 160          6.0  \n",
      "4760                          405 004          2.0  \n",
      "161                           617 117          2.0  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"Store Indus non-core region texts\"\"\"\n",
    "#indus_non_core_sites = ['Altin Yepe', 'Hajar', 'Ra\\'s al-Junayz', 'Qala\\'at al-Bahrain', 'Failaka', 'Kish', 'Nippur','Luristan', 'Susa', 'Altyn Depe', 'Tepe Yahya', 'Tello']\n",
    "    \n",
    "df_indus_non_core_region = None\n",
    "    \n",
    "for indus_non_core_site in indus_non_core_sites:\n",
    "    df_temp = df[df['site'].str.contains(indus_non_core_site) == True]\n",
    "    frames = [df_temp, df_indus_non_core_region]\n",
    "    df_indus_non_core_region  = pd.concat(frames)\n",
    "    \n",
    "print(\"Indus non-core region site texts\", indus_non_core_sites , \" has \", len(df_indus_non_core_region.index), \" rows\")\n",
    "print(df_indus_non_core_region)\n",
    "\n",
    "df_indus_non_core_region.to_pickle('pickle/non_core_df.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4def047",
   "metadata": {},
   "source": [
    "# Unclear Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb3c88ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1054  rows of unclear texts\n",
      "After removing duplicate texts, we have  763  rows\n",
      "After removing multi-line text, we have  728  rows\n",
      "After keeping only text with known direction, we have  586  rows\n",
      "After keeping only text without multipart, we have  291  rows\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Keep the items with unclear text in another dataframe\"\"\"\n",
    "df_unclear = df_filtered[df_filtered['l_to_r_text'].str.contains('000') == True]\n",
    "\n",
    "print(\"We have\", len(df_unclear.index), \" rows of unclear texts\")\n",
    "\n",
    "if(drop_duplicate_texts):\n",
    "    #Remove out duplicate inplace\n",
    "    # TBD How can unclear text be duplicates\n",
    "    df_unclear  =df_unclear.drop_duplicates(subset =\"text\",\n",
    "                         keep = False, inplace = False)\n",
    "\n",
    "    print(\"After removing duplicate texts, we have \", len(df_unclear.index), \" rows\")\n",
    "\n",
    "#keep only the values that does not have multi-line text\n",
    "df_unclear= df_unclear[df_unclear['text'].str.contains('/') == False] \n",
    "\n",
    "print(\"After removing multi-line text, we have \", len(df_unclear.index), \" rows\")\n",
    "\n",
    "\n",
    "\"\"\"Single sign ones don't have direction and won't have /, wo we need to explicitly include it\n",
    " Btw standardized_text is Left to right as in English\n",
    " df = df[df['direction'].str.contains('/') == True]  \"\"\"\n",
    "df_unclear= df_unclear[(df_unclear['direction'].str.contains('/') == True) | (df_unclear['text_length'] ==1)] \n",
    "\n",
    "print(\"After keeping only text with known direction, we have \", len(df_unclear.index), \" rows\")\n",
    "\n",
    "#Remove Multipart texts that have [ or ]\n",
    "df_unclear= df_unclear[df_unclear['text'].str.contains(\"\\[\") == False] \n",
    "df_unclear= df_unclear[df_unclear['text'].str.contains(\"\\]\") == False] \n",
    "\n",
    "print(\"After keeping only text without multipart, we have \", len(df_unclear.index), \" rows\")\n",
    "\n",
    "#Note: Lot of the text with unclear text have direction empty\n",
    "\n",
    "\"\"\"Pickle it\"\"\"\n",
    "df_unclear.to_pickle('pickle/unclear_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd15783",
   "metadata": {},
   "source": [
    "# Multi Line Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b93e3802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe has  4999  rows\n",
      "After removing unclear texts, we have  3945  rows\n",
      "After removing duplicate texts, we have  2130  rows\n",
      "We have 77  rows of multi line texts\n",
      "69                      +032-031/151-740-240-235+\n",
      "71              +032-031/850-032-530-740-741-456+\n",
      "72                          +032-031/740-791-713+\n",
      "74                              +032/226-032-817+\n",
      "80                          +740-636-240/002-817+\n",
      "                          ...                    \n",
      "4386                    +621/090-740-231-560-534+\n",
      "4402                +790/740-100-415-740-257-840+\n",
      "4705                        +740-900-003/741-002+\n",
      "4729                                    +840/790+\n",
      "4752    +605-740-142-067/002-374-310-350-495-834+\n",
      "Name: text, Length: 77, dtype: object\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Keep the text that are multiline (has ''/'') in another dataframe \"\"\"\n",
    "\n",
    "print(\"Dataframe has \", len(df_filtered.index), \" rows\")\n",
    "\n",
    "\"\"\" remove the values where the text is unclear\"\"\"\n",
    "df_multi_line = df_filtered[df_filtered['l_to_r_text'].str.contains('000') == False] \n",
    "\n",
    "print(\"After removing unclear texts, we have \", len(df_multi_line.index), \" rows\")\n",
    "\n",
    "if(drop_duplicate_texts):\n",
    "    #Remove out duplicate inplace\n",
    "    df_multi_line = df_multi_line.drop_duplicates(subset =\"text\",\n",
    "                         keep = False, inplace = False)\n",
    "\n",
    "    print(\"After removing duplicate texts, we have \", len(df_multi_line.index), \" rows\")\n",
    "\n",
    "\n",
    "#keep only the values that has multi-line text\n",
    "df_multi_line = df_multi_line[df_multi_line['text'].str.contains('/') == True] \n",
    "\n",
    "print(\"We have\", len(df_multi_line.index), \" rows of multi line texts\")\n",
    "print(df_multi_line.text)\n",
    "\n",
    "df_multi_line.to_csv('multi_line_texts.csv')\n",
    "\n",
    "\"\"\"Pickle it\"\"\"\n",
    "df_multi_line.to_pickle('pickle/multi_line_df.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de932926",
   "metadata": {},
   "source": [
    "### Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36748bc1",
   "metadata": {},
   "source": [
    "\"\"\"We will keep All data, All Indus Core, Train data and Test data\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8b9394",
   "metadata": {},
   "source": [
    "## All data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56c6896b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2223,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_all = df['site'].values\n",
    "y_all.shape\n",
    "\n",
    "y=df['site'].values\n",
    "y.shape\n",
    "\n",
    "# y axis is still the same\n",
    "y_all_rev=df['site'].values\n",
    "y_all_rev.shape\n",
    "\n",
    "y_rev=df['site'].values\n",
    "y_rev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "639a81d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2223,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "x_all = np.asarray(df[['l_to_r_text', 'direction', 'icit_id']])\n",
    "x_all.shape\n",
    "\n",
    "x = np.asarray(df[['l_to_r_text', 'direction', 'icit_id']])\n",
    "x.shape\n",
    "\n",
    "x_all_rev=df['reversed_text'].values\n",
    "x_all_rev.shape\n",
    "\n",
    "x_rev=df['reversed_text'].values\n",
    "x_rev.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40cd4251",
   "metadata": {},
   "source": [
    "## Indus Core region data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "665cca4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2213,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_core = df_indus_core_region['site'].values\n",
    "y_core.shape\n",
    "\n",
    "# y axis is still the same\n",
    "y_core_rev=df_indus_core_region['site'].values\n",
    "y_core_rev.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b7c019d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2213,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_core = np.asarray(df_indus_core_region[['l_to_r_text', 'direction', 'icit_id']])\n",
    "x_core.shape\n",
    "\n",
    "x_core_rev=df_indus_core_region['reversed_text'].values\n",
    "x_core_rev.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8e872a",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "655255c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev(df_in):\n",
    "    list_reversed_text = []\n",
    "    for text in df_in.l_to_r_text:\n",
    "        chars = text.split(' ')\n",
    "        reversed_text = ' '.join(reversed(chars))\n",
    "        list_reversed_text.append(reversed_text)\n",
    "        \n",
    "    new_df=pd.DataFrame()\n",
    "    new_df['reversed_text']= list_reversed_text\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f8ac3ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f0e4b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Split the data into Train and Test\"\"\"\n",
    "(x_train,x_test,y_train,y_test)=train_test_split(x,y,test_size=0.20, random_state=43)\n",
    "\n",
    "#(x_rev_train,x_rev_test,y_rev_train,y_rev_test)=train_test_split(x_rev,y_rev,test_size=0.25, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2dc6eea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Split the Indus Core region data into Train and Test\"\"\"\n",
    "(x_core_train,x_core_test,y_core_train,y_core_test)=train_test_split(x_core,y_core,test_size=0.20, random_state=43)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9f501b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Build dataframe out of train and test data\"\"\"\n",
    "\n",
    "df_train_x1=pd.DataFrame(x_train)\n",
    "df_train_x1=df_train_x1.rename(columns={0:'l_to_r_text'})\n",
    "df_train_x1_rev = rev(df_train_x1)\n",
    "x_rev_train = np.asarray(df_train_x1_rev[['reversed_text']])\n",
    "#print(\"_____x_train:\", x_train.shape, x_train)\n",
    "#print(\"_____x_rev_train:\", x_rev_train.shape, x_rev_train)\n",
    "y_rev_train = y_train\n",
    "\n",
    "df_test_x1=pd.DataFrame(x_test)\n",
    "df_test_x1=df_test_x1.rename(columns={0:'l_to_r_text'})\n",
    "df_test_x1_rev = rev(df_test_x1)\n",
    "x_rev_test = np.asarray(df_test_x1_rev[['reversed_text']])\n",
    "#print(\"_____x_test:\", x_test.shape, x_test)\n",
    "#print(\"_____x_rev_test:\", x_rev_test.shape, x_rev_test)\n",
    "\n",
    "y_rev_test = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3424177d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Build dataframe out of Indus Core Region train and test data\"\"\"\n",
    "\n",
    "df_core_train_x1=pd.DataFrame(x_core_train)\n",
    "df_core_train_x1=df_core_train_x1.rename(columns={0:'l_to_r_text'})\n",
    "df_core_train_x1_rev = rev(df_core_train_x1)\n",
    "x_rev_core_train = np.asarray(df_core_train_x1_rev[['reversed_text']])\n",
    "#print(\"_____x_core_train:\", x_core_train.shape, x_core_train)\n",
    "#print(\"_____x_rev_core_train:\", x_rev_core_train.shape, x_rev_core_train)\n",
    "y_rev_core_train = y_core_train\n",
    "\n",
    "df_core_test_x1=pd.DataFrame(x_core_test)\n",
    "df_core_test_x1=df_core_test_x1.rename(columns={0:'l_to_r_text'})\n",
    "df_core_test_x1_rev = rev(df_core_test_x1)\n",
    "x_rev_core_test = np.asarray(df_core_test_x1_rev[['reversed_text']])\n",
    "#print(\"_____x_core_test:\", x_core_test.shape, x_core_test)\n",
    "#print(\"_____x_rev_core_test:\", x_rev_core_test.shape, x_rev_core_test)\n",
    "\n",
    "y_rev_core_test = y_core_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58c150cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(x_rev_train,x_rev_test,y_rev_train,y_rev_test)=train_test_split(x_rev,y_rev,test_size=0.10, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "144e06e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"All data, fwd and reverse\"\"\"\n",
    "df_all_x=pd.DataFrame(x_all)\n",
    "df_all_x=df_all_x.rename(columns={0:'l_to_r_text'})\n",
    "df_all_x=df_all_x.rename(columns={1:'direction'})\n",
    "df_all_x=df_all_x.rename(columns={2:'icit_id'})\n",
    "\n",
    "df_all_y=pd.DataFrame(y_all)\n",
    "df_all_y=df_all_y.rename(columns={0:'site'})\n",
    "\n",
    "#rev\n",
    "df_all_x_rev=pd.DataFrame(x_all_rev)\n",
    "df_all_x_rev=df_all_x_rev.rename(columns={0:'reversed_text'})\n",
    "\n",
    "df_all_y_rev=pd.DataFrame(y_all_rev)\n",
    "df_all_y_rev=df_all_y_rev.rename(columns={0:'site'})\n",
    "\n",
    "#Train data, fwd and reverse\n",
    "df_train_x=pd.DataFrame(x_train)\n",
    "df_train_x=df_train_x.rename(columns={0:'l_to_r_text'})\n",
    "df_train_x=df_train_x.rename(columns={1:'direction'})\n",
    "df_train_x=df_train_x.rename(columns={2:'icit_id'})\n",
    "\n",
    "df_train_y=pd.DataFrame(y_train)\n",
    "df_train_y=df_train_y.rename(columns={0:'site'})\n",
    "\n",
    "#rev\n",
    "df_train_x_rev=pd.DataFrame(x_rev_train)\n",
    "df_train_x_rev=df_train_x_rev.rename(columns={0:'reversed_text'})\n",
    "\n",
    "\n",
    "df_train_y_rev=pd.DataFrame(y_rev_train)\n",
    "df_train_y_rev=df_train_y_rev.rename(columns={0:'site'})\n",
    "\n",
    "#Test data, fwd and reverse\n",
    "df_test_x=pd.DataFrame(x_test)\n",
    "df_test_x=df_test_x.rename(columns={0:'l_to_r_text'})\n",
    "df_test_x=df_test_x.rename(columns={1:'direction'})\n",
    "df_test_x=df_test_x.rename(columns={2:'icit_id'})\n",
    "\n",
    "df_test_y=pd.DataFrame(y_test)\n",
    "df_test_y=df_test_y.rename(columns={0:'site'})\n",
    "\n",
    "#rev\n",
    "df_test_x_rev=pd.DataFrame(x_rev_test)\n",
    "df_test_x_rev=df_test_x_rev.rename(columns={0:'reversed_text'})\n",
    "\n",
    "df_test_y_rev=pd.DataFrame(y_rev_test)\n",
    "df_test_y_rev=df_test_y_rev.rename(columns={0:'site'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "19b1698f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Indus Core Region  data - Test and Train fwd and reverse\"\"\"\n",
    "\n",
    "\"\"\"Core Region data, fwd and reverse\"\"\"\n",
    "df_core_x=pd.DataFrame(x_core)\n",
    "df_core_x=df_core_x.rename(columns={0:'l_to_r_text'})\n",
    "df_core_x=df_core_x.rename(columns={1:'direction'})\n",
    "df_core_x=df_core_x.rename(columns={2:'icit_id'})\n",
    "\n",
    "df_core_y=pd.DataFrame(y_core)\n",
    "df_core_y=df_core_y.rename(columns={0:'site'})\n",
    "\n",
    "#rev\n",
    "df_core_x_rev=pd.DataFrame(x_core_rev)\n",
    "df_core_x_rev=df_core_x_rev.rename(columns={0:'reversed_text'})\n",
    "\n",
    "df_core_y_rev=pd.DataFrame(y_core_rev)\n",
    "df_core_y_rev=df_core_y_rev.rename(columns={0:'site'})\n",
    "\n",
    "\n",
    "#Train data, fwd and reverse\n",
    "df_core_train_x=pd.DataFrame(x_core_train)\n",
    "df_core_train_x=df_core_train_x.rename(columns={0:'l_to_r_text'})\n",
    "df_core_train_x=df_core_train_x.rename(columns={1:'direction'})\n",
    "df_core_train_x=df_core_train_x.rename(columns={2:'icit_id'})\n",
    "\n",
    "df_core_train_y=pd.DataFrame(y_core_train)\n",
    "df_core_train_y=df_core_train_y.rename(columns={0:'site'})\n",
    "\n",
    "#rev\n",
    "df_core_train_x_rev=pd.DataFrame(x_rev_core_train)\n",
    "df_core_train_x_rev=df_core_train_x_rev.rename(columns={0:'reversed_text'})\n",
    "\n",
    "\n",
    "df_core_train_y_rev=pd.DataFrame(y_rev_core_train)\n",
    "df_core_train_y_rev=df_core_train_y_rev.rename(columns={0:'site'})\n",
    "\n",
    "#Test data, fwd and reverse\n",
    "df_core_test_x=pd.DataFrame(x_core_test)\n",
    "df_core_test_x=df_core_test_x.rename(columns={0:'l_to_r_text'})\n",
    "df_core_test_x=df_core_test_x.rename(columns={1:'direction'})\n",
    "df_core_test_x=df_core_test_x.rename(columns={2:'icit_id'})\n",
    "\n",
    "df_core_test_y=pd.DataFrame(y_core_test)\n",
    "df_core_test_y=df_core_test_y.rename(columns={0:'site'})\n",
    "\n",
    "#rev\n",
    "df_core_test_x_rev=pd.DataFrame(x_rev_core_test)\n",
    "df_core_test_x_rev=df_core_test_x_rev.rename(columns={0:'reversed_text'})\n",
    "\n",
    "df_core_test_y_rev=pd.DataFrame(y_rev_core_test)\n",
    "df_core_test_y_rev=df_core_test_y_rev.rename(columns={0:'site'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5885aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Pickle the data\"\"\"\n",
    "df_core_x.to_pickle('pickle/core_x.pkl')\n",
    "df_core_y.to_pickle('pickle/core_y.pkl')\n",
    "\n",
    "df_core_x_rev.to_pickle('pickle/core_x_rev.pkl')\n",
    "df_core_y_rev.to_pickle('pickle/core_y_rev.pkl')\n",
    "\n",
    "df_train_x.to_pickle('pickle/train_x.pkl')\n",
    "df_train_y.to_pickle('pickle/train_y.pkl')\n",
    "\n",
    "df_train_x_rev.to_pickle('pickle/train_x_rev.pkl')\n",
    "df_train_y_rev.to_pickle('pickle/train_y_rev.pkl')\n",
    "\n",
    "df_test_x.to_pickle('pickle/test_x.pkl')\n",
    "df_test_y.to_pickle('pickle/test_y.pkl')\n",
    "\n",
    "df_test_x_rev.to_pickle('pickle/test_x_rev.pkl')\n",
    "df_test_y_rev.to_pickle('pickle/test_y_rev.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "357ed225",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Pickle the Indus Core Region data\"\"\"\n",
    "\n",
    "df_all_x.to_pickle('pickle/all_x.pkl')\n",
    "df_all_y.to_pickle('pickle/all_y.pkl')\n",
    "\n",
    "df_all_x_rev.to_pickle('pickle/all_x_rev.pkl')\n",
    "df_all_y_rev.to_pickle('pickle/all_y_rev.pkl')\n",
    "\n",
    "\n",
    "df_core_train_x.to_pickle('pickle/core_train_x.pkl')\n",
    "df_core_train_y.to_pickle('pickle/core_train_y.pkl')\n",
    "\n",
    "df_core_train_x_rev.to_pickle('pickle/core_train_x_rev.pkl')\n",
    "df_core_train_y_rev.to_pickle('pickle/core_train_y_rev.pkl')\n",
    "\n",
    "df_core_test_x.to_pickle('pickle/core_test_x.pkl')\n",
    "df_core_test_y.to_pickle('pickle/core_test_y.pkl')\n",
    "\n",
    "df_core_test_x_rev.to_pickle('pickle/core_test_x_rev.pkl')\n",
    "df_core_test_y_rev.to_pickle('pickle/core_test_y_rev.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bcf71ca4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       l_to_r_text direction icit_id        site\n",
      "0          410 017       L/R       1  Alamgirpur\n",
      "1          405 017       L/R       3  Alamgirpur\n",
      "2          235 740       R/L       5   Allahdino\n",
      "3      590 390 740       R/L       6   Allahdino\n",
      "4  033 125 390 368       R/L       7   Allahdino\n",
      "                   l_to_r_text direction icit_id          site\n",
      "0                          013        NR    2032        Lothal\n",
      "1                      700 034       R/L     938       Harappa\n",
      "2                  590 407 740       R/L    1874         Hulas\n",
      "3      820 002 806 590 405 740       R/L    3611  Mohenjo-daro\n",
      "4  140 920 484 337 503 456 400       R/L    3578  Mohenjo-daro\n",
      "                   l_to_r_text direction icit_id          site\n",
      "0                      003 390       R/L    2191  Mohenjo-daro\n",
      "1                  235 240 520       R/L    1189       Harappa\n",
      "2  861 002 003 220 590 405 740       R/L    1175       Harappa\n",
      "3                          820        NR     912       Harappa\n",
      "4  140 287 002 415 220 879 740       R/L    2636  Mohenjo-daro\n",
      "     reversed_text        site\n",
      "0          017 410  Alamgirpur\n",
      "1          017 405  Alamgirpur\n",
      "2          740 235   Allahdino\n",
      "3      740 390 590   Allahdino\n",
      "4  368 390 125 033   Allahdino\n",
      "                 reversed_text          site\n",
      "0                          013        Lothal\n",
      "1                      034 700       Harappa\n",
      "2                  740 407 590         Hulas\n",
      "3      740 405 590 806 002 820  Mohenjo-daro\n",
      "4  400 456 503 337 484 920 140  Mohenjo-daro\n",
      "                 reversed_text          site\n",
      "0                      390 003  Mohenjo-daro\n",
      "1                  520 240 235       Harappa\n",
      "2  740 405 590 220 003 002 861       Harappa\n",
      "3                          820       Harappa\n",
      "4  740 879 220 415 002 287 140  Mohenjo-daro\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Create and Pickle All, test and train Dataframes fwd, rev \"\"\"\n",
    "\n",
    "df_all=pd.concat([df_all_x,df_all_y],axis=1)\n",
    "print(df_all.head())\n",
    "\n",
    "df_train=pd.concat([df_train_x,df_train_y],axis=1)\n",
    "print(df_train.head())\n",
    "\n",
    "df_test=pd.concat([df_test_x,df_test_y],axis=1)\n",
    "print(df_test.head())\n",
    "\n",
    "df_all_rev=pd.concat([df_all_x_rev,df_all_y_rev],axis=1)\n",
    "print(df_all_rev.head())\n",
    "\n",
    "df_train_rev=pd.concat([df_train_x_rev,df_train_y_rev],axis=1)\n",
    "print(df_train_rev.head())\n",
    "\n",
    "df_test_rev=pd.concat([df_test_x_rev,df_test_y_rev],axis=1)\n",
    "print(df_test_rev.head())\n",
    "\n",
    "\"\"\"Pickle all the dataframes we need\"\"\"\n",
    "df_all.to_pickle('pickle/all_df.pkl')\n",
    "df_train.to_pickle('pickle/train_df.pkl')\n",
    "df_test.to_pickle('pickle/test_df.pkl')\n",
    "df_all_rev.to_pickle('pickle/all_rev_df.pkl')\n",
    "df_train_rev.to_pickle('pickle/train_rev_df.pkl')\n",
    "df_test_rev.to_pickle('pickle/test_rev_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "86dfa2bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       l_to_r_text direction icit_id        site\n",
      "0          410 017       L/R       1  Alamgirpur\n",
      "1          405 017       L/R       3  Alamgirpur\n",
      "2          235 740       R/L       5   Allahdino\n",
      "3      590 390 740       R/L       6   Allahdino\n",
      "4  033 125 390 368       R/L       7   Allahdino\n",
      "                   l_to_r_text direction icit_id          site\n",
      "0  513 460 036 861 002 005 390       R/L    2548  Mohenjo-daro\n",
      "1                  176 100 740       R/L    1213       Harappa\n",
      "2                      003 156       R/L    2307  Mohenjo-daro\n",
      "3                      220 520       R/L     282       Harappa\n",
      "4                  140 706 064       R/L    1194       Harappa\n",
      "               l_to_r_text direction icit_id          site\n",
      "0      798 233 790 900 740       R/L    2648  Mohenjo-daro\n",
      "1  861 368 001 803 235 520       R/L    3219  Mohenjo-daro\n",
      "2          244 065 880 820       R/L    2535  Mohenjo-daro\n",
      "3                  005 390       R/L    2472  Mohenjo-daro\n",
      "4              235 803 740       R/L    2476  Mohenjo-daro\n",
      "     reversed_text        site\n",
      "0          017 410  Alamgirpur\n",
      "1          017 405  Alamgirpur\n",
      "2          740 235   Allahdino\n",
      "3      740 390 590   Allahdino\n",
      "4  368 390 125 033   Allahdino\n",
      "                 reversed_text          site\n",
      "0  390 005 002 861 036 460 513  Mohenjo-daro\n",
      "1                  740 100 176       Harappa\n",
      "2                      156 003  Mohenjo-daro\n",
      "3                      520 220       Harappa\n",
      "4                  064 706 140       Harappa\n",
      "             reversed_text          site\n",
      "0      740 900 790 233 798  Mohenjo-daro\n",
      "1  520 235 803 001 368 861  Mohenjo-daro\n",
      "2          820 880 065 244  Mohenjo-daro\n",
      "3                  390 005  Mohenjo-daro\n",
      "4              740 803 235  Mohenjo-daro\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Create and Pickle Indus Core Dataframes, fwd, rev\"\"\"\n",
    "\n",
    "df_core=pd.concat([df_core_x,df_core_y],axis=1)\n",
    "print(df_core.head())\n",
    "\n",
    "df_core_train=pd.concat([df_core_train_x,df_core_train_y],axis=1)\n",
    "print(df_core_train.head())\n",
    "\n",
    "df_core_test=pd.concat([df_core_test_x,df_core_test_y],axis=1)\n",
    "print(df_core_test.head())\n",
    "\n",
    "df_core_rev=pd.concat([df_core_x_rev,df_core_y_rev],axis=1)\n",
    "print(df_core_rev.head())\n",
    "\n",
    "\n",
    "df_core_train_rev=pd.concat([df_core_train_x_rev,df_core_train_y_rev],axis=1)\n",
    "print(df_core_train_rev.head())\n",
    "\n",
    "df_core_test_rev=pd.concat([df_core_test_x_rev,df_core_test_y_rev],axis=1)\n",
    "print(df_core_test_rev.head())\n",
    "\n",
    "\"\"\"Pickle all the dataframes we need\"\"\"\n",
    "df_core.to_pickle('pickle/core_df.pkl')\n",
    "df_core_train.to_pickle('pickle/core_train_df.pkl')\n",
    "df_core_test.to_pickle('pickle/core_test_df.pkl')\n",
    "\n",
    "df_core_rev.to_pickle('pickle/core_rev_df.pkl')\n",
    "df_core_train_rev.to_pickle('pickle/core_train_rev_df.pkl')\n",
    "df_core_test_rev.to_pickle('pickle/core_test_rev_df.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
